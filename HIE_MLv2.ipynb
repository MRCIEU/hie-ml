{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Hypoxic Ischemic Encephalopathy from Collaborative Perinatal Project using ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upgrade tensorflow\n",
    "! pip install grpcio==1.24.3\n",
    "! pip install tensorflow==2.0.0\n",
    "! pip install -U ray==0.7.6\n",
    "\n",
    "# install imbalance lib\n",
    "! pip install imbalanced-learn==0.5.0\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import brier_score_loss, roc_curve, auc\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from ray.tune.integration.keras import TuneReporterCallback\n",
    "from ray.tune.examples.utils import get_mnist_data\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.set(style=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(pred, out):\n",
    "    # fit RF with all variables using five-fold CV\n",
    "    clf = RandomForestClassifier(random_state=0, n_estimators=100)\n",
    "    \n",
    "    # get feature importance measures\n",
    "    clf.fit(pred, out.to_numpy())\n",
    "    fi = pd.DataFrame(data={'predictor' : pred.columns, 'feature_importance': clf.feature_importances_})\n",
    "    \n",
    "    return fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(clf, x_train, y_train, x_test, y_test):   \n",
    "    # train model\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    # calculate probabilities for test data\n",
    "    y_test_pred = clf.predict_proba(x_test)[:, 1]\n",
    "    \n",
    "    # calculate roc auc metric\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_test_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # calculate brier loss for probability accuracy\n",
    "    brier_loss = brier_score_loss(y_test, y_test_pred)\n",
    "    \n",
    "    print(\"ROC AUC: {}\\nBrier loss: {}\".format(np.round(roc_auc, 3), np.round(brier_loss, 3)))\n",
    "    \n",
    "    return y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_nn(model, x_train, y_train, x_test, y_test):\n",
    "    print(\"x_train n={} y_train n={} x_test n={} y_test n={}\".format(len(x_train), len(y_train), len(x_test), len(y_test)))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "    \n",
    "    # train model\n",
    "    model.fit(tf.convert_to_tensor(x_train.to_numpy(), np.float32), tf.convert_to_tensor(y_train.to_numpy(), np.float32), epochs=15)\n",
    "    \n",
    "    # predict test probabilities\n",
    "    y_test_pred = model.predict(tf.convert_to_tensor(x_test.to_numpy(), np.float32))\n",
    "    \n",
    "    # calculate roc auc metric\n",
    "    fpr, tpr, thresholds = roc_curve(y_test.to_numpy(), y_test_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # calculate brier loss for probability accuracy\n",
    "    brier_loss = brier_score_loss(y_test.to_numpy(), y_test_pred)\n",
    "    \n",
    "    print(\"ROC AUC: {}\\nBrier loss: {}\".format(np.round(roc_auc, 3), np.round(brier_loss, 3)))\n",
    "    \n",
    "    return y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df, numeric_features, means, stds):\n",
    "    \n",
    "    # normalise continuous variables\n",
    "    for i, f in enumerate(numeric_features):\n",
    "        if f in df.columns:\n",
    "            df[f] = (df[f] - means[i]) / stds[i]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_feature_select_threshold(X, y, threshold=0.01):\n",
    "    clf = RandomForestClassifier(random_state=0, n_estimators=100)\n",
    "    clf = clf.fit(X, y)\n",
    "    return X.columns[clf.feature_importances_ > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(config, reporter):\n",
    "    # https://github.com/tensorflow/tensorflow/issues/32159\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import (Dense, Dropout, Flatten, Conv2D,\n",
    "                                         MaxPooling2D)\n",
    "    batch_size = 128\n",
    "    num_classes = 10\n",
    "    epochs = 12\n",
    "\n",
    "    x_train, y_train, x_test, y_test, input_shape = get_mnist_data()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            32, kernel_size=(3, 3), activation=\"relu\",\n",
    "            input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(config[\"hidden\"], activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.categorical_crossentropy,\n",
    "        optimizer=tf.keras.optimizers.SGD(\n",
    "            lr=config[\"lr\"], momentum=config[\"momentum\"]),\n",
    "        metrics=[\"accuracy\"])\n",
    "\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=0,\n",
    "        validation_data=(x_test, y_test),\n",
    "        callbacks=[TuneReporterCallback(reporter)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data\n",
    "The first(A) is one with all variables with >5% missing values removed, the second(B) is imputed form the most recent complete data-point prior to that birth and the third(C) is imputed using mode values\n",
    "\n",
    "Derived variables are:\n",
    "- _cohort – Either 1 (born in the first deriving cohort) or 0 (in the second, testing cohort)\n",
    "- _hie – 1 for HIE, 0 for not\n",
    "- _id\n",
    "- _lapgar – 1 for a low Apgar score, 0 for not\n",
    "- _ne – Another measure of brain injury (not used at present)\n",
    "- _neonataldeath – Not used at present\n",
    "- _perinataldeath – 1 for perinatal death; 0 for not\n",
    "- _resus – 1 for resus at birth, and 0 for not\n",
    "- _stillborn – Not used at present\n",
    "- _yearofbirth -  Year of birth\n",
    "\n",
    "First letter is either a (antenatal), g (growth) or I (intrapartum) variable\n",
    "Second letter is type of entry; c (categorical), o(ordinal) or l(linear)\n",
    "Then _NAME (most have one given)\n",
    "Then _#### - number of were extraction was performed on the [Variable File](\"3. Index_Variable File_304.2ADV3A.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data from DO\n",
    "dat = pd.read_stata(\"data/1_2_3_4A._Done.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sep cols\n",
    "antenatal = []\n",
    "antenatal_growth = []\n",
    "antenatal_intrapartum = []\n",
    "categorical = []\n",
    "ordinal = []\n",
    "linear = []\n",
    "\n",
    "for col in dat.columns:\n",
    "    if col[0] == \"_\":\n",
    "        continue\n",
    "    if col[0] == \"a\":\n",
    "        antenatal.append(col)\n",
    "        antenatal_growth.append(col)\n",
    "        antenatal_intrapartum.append(col)\n",
    "    if col[0] == \"g\":\n",
    "        antenatal_growth.append(col)\n",
    "    if col[0] == \"i\":\n",
    "        antenatal_intrapartum.append(col)\n",
    "    if col[1] == \"c\":\n",
    "        categorical.append(col)\n",
    "    if col[1] == \"o\":\n",
    "        ordinal.append(col)\n",
    "    if col[1] == \"l\":\n",
    "        linear.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set fields correctly\n",
    "outcomes = ['_hie', '_lapgar', '_perinataldeath', '_resus']\n",
    "dat[categorical] = dat[categorical].astype('category')\n",
    "dat[outcomes] = dat[outcomes].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test and train\n",
    "test = dat[dat['_cohort'] == 0]\n",
    "train = dat[dat['_cohort'] == 1]\n",
    "\n",
    "## get mean and SD for **training** dataset to standardise variables (where needed)\n",
    "desc = train[linear].describe()\n",
    "means = np.array(desc.T['mean'])\n",
    "stds = np.array(desc.T['std'])\n",
    "\n",
    "def split_data(df, x_cols, y_col):\n",
    "    x = df[x_cols + [y_col]]\n",
    "    x = x.dropna(axis='index')\n",
    "    y = x.pop(y_col)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All(?) we need from the ML model is one which takes the outcomes (HIE (Primary outcome), Low Apgar, Perinatal Death and Resus) and builds 3 prediction models. First is only antenatal variables (a*), then next is antenatal and growth (a* and g*) and then antenatal and intrapartum (a* and i*). From each model the idea to produce a prediction score from cohort 1, and apply to cohort 0, derive an ROC/AUC score for the prediction, creating a variable containing which deciles of risk the infant is placed in (1-10) – in order to compare with the other models being developed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antenatal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HIE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split out data\n",
    "train_x, train_y = split_data(train, antenatal, '_hie')\n",
    "test_x, test_y = split_data(test, antenatal, '_hie')\n",
    "\n",
    "# over sample minority class\n",
    "train_x_resampled, train_y_resampled = SMOTE(random_state=0).fit_resample(train_x, train_y)\n",
    "train_x_resampled = pd.DataFrame(train_x_resampled, columns=train_x.columns)\n",
    "train_y_resampled = pd.DataFrame(train_y_resampled, columns=[train_y.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features where FI > threshold\n",
    "keep = rf_feature_select_threshold(train_x_resampled, train_y_resampled)\n",
    "\n",
    "## select features\n",
    "train_x_resampled = train_x_resampled[keep]\n",
    "test_x = test_x[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance measures for variables that contribute to the model\n",
    "fi = get_feature_importance(train_x_resampled, train_y_resampled)\n",
    "ax = sns.barplot(y='predictor', x=\"feature_importance\", data=fi.sort_values('feature_importance', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs', max_iter=100000)\n",
    "y_test_pred = fit(clf, train_x_resampled, train_y_resampled, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=100)\n",
    "y_test_pred = fit(clf, train_x_resampled, train_y_resampled, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise continuous values\n",
    "train_x_resampled = process_data(train_x_resampled, linear, means, stds)\n",
    "test_x = process_data(test_x, linear, means, stds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
