{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install imbalance lib\n",
    "! pip install -q imbalanced-learn==0.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(train_x, train_y):\n",
    "    # over sample minority class\n",
    "    train_x_resampled, train_y_resampled = SMOTE(random_state=0).fit_resample(train_x, train_y)\n",
    "    train_x_resampled = pd.DataFrame(train_x_resampled, columns=train_x.columns)\n",
    "    train_y_resampled = pd.DataFrame(train_y_resampled, columns=[train_y.name])\n",
    "    \n",
    "    return train_x_resampled, train_y_resampled\n",
    "\n",
    "def rf_feature_select_threshold(X, y, threshold=0.01):\n",
    "    clf = RandomForestClassifier(random_state=0, n_estimators=100)\n",
    "    clf = clf.fit(X.values, y.values.ravel())\n",
    "    fi = pd.DataFrame(data={'predictor' : X.columns, 'feature_importance': clf.feature_importances_})\n",
    "    return X.columns[clf.feature_importances_ > threshold]\n",
    "\n",
    "def standardize_continuous_values(df, continuous_features, means, stds):\n",
    "    for i, f in enumerate(continuous_features):\n",
    "        if f in df.columns:\n",
    "            df[f] = (df[f] - means[i]) / stds[i]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get mean and SD for **training** dataset to standardise variables\n",
    "desc = train[linear + ordinal].describe()\n",
    "means = np.array(desc.T['mean'])\n",
    "stds = np.array(desc.T['std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, variable_list in {\"antenatal\" : antenatal, \"antenatal_growth\" : antenatal_growth, \"antenatal_intrapartum\" : antenatal_intrapartum}.items():\n",
    "    for outcome in ['_hie', '_lapgar', '_perinataldeath', '_resus']:\n",
    "        print(\"Working on {} for {}\".format(name, outcome))\n",
    "        \n",
    "        # select variables for this analysis\n",
    "        train_x, train_y = split_data(train, variable_list, outcome)\n",
    "        test_x, test_y = split_data(test, variable_list, outcome)\n",
    "        \n",
    "        # resample the minor class\n",
    "        train_x, train_y = resample(train_x, train_y)\n",
    "        \n",
    "        # identify highly correlated features\n",
    "        corr_matrix = train_x.corr().abs()\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "        to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\n",
    "        \n",
    "        # drop one highly correlated feature from a pair\n",
    "        print(\"Dropping correlated features: {}\".format(to_drop))\n",
    "        train_x = train_x.drop(to_drop, axis=1)\n",
    "        test_x = test_x.drop(to_drop, axis=1)\n",
    "\n",
    "        # feature selection using random forest\n",
    "        keep = rf_feature_select_threshold(train_x, train_y)\n",
    "        print(\"Selected features: {}\".format(list(keep)))\n",
    "        train_x = train_x[keep]\n",
    "        test_x = test_x[keep]\n",
    "        \n",
    "        # standardize continuous values\n",
    "        train_x = standardize_continuous_values(train_x, linear + ordinal, means, stds)\n",
    "        test_x = standardize_continuous_values(test_x, linear + ordinal, means, stds)\n",
    "\n",
    "        # write to csv\n",
    "        pd.concat([train_x, train_y], axis=1).to_csv(\"data/{}{}_train.csv\".format(name, outcome), header=True)\n",
    "        pd.concat([test_x, test_y], axis=1).to_csv(\"data/{}{}_test.csv\".format(name, outcome), header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
