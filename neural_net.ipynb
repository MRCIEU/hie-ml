{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upgrade tensorflow\n",
    "! pip install -q grpcio==1.24.3\n",
    "! pip install -q tensorflow==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import brier_score_loss, roc_curve, auc\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running NN on antenatal for _hie\n",
      "Train on 26126 samples\n",
      "Epoch 1/20\n",
      "26126/26126 [==============================] - 2s 87us/sample - loss: 0.4264 - AUC: 0.8873\n",
      "Epoch 2/20\n",
      "26126/26126 [==============================] - 2s 64us/sample - loss: 0.2589 - AUC: 0.9574\n",
      "Epoch 3/20\n",
      "26126/26126 [==============================] - 2s 65us/sample - loss: 0.1606 - AUC: 0.9804\n",
      "Epoch 4/20\n",
      "26126/26126 [==============================] - 2s 67us/sample - loss: 0.1161 - AUC: 0.9879\n",
      "Epoch 5/20\n",
      "26126/26126 [==============================] - 2s 63us/sample - loss: 0.0942 - AUC: 0.9912\n",
      "Epoch 6/20\n",
      "26126/26126 [==============================] - 2s 67us/sample - loss: 0.0799 - AUC: 0.9929\n",
      "Epoch 7/20\n",
      "26126/26126 [==============================] - 2s 65us/sample - loss: 0.0692 - AUC: 0.9944\n",
      "Epoch 8/20\n",
      "26126/26126 [==============================] - 2s 63us/sample - loss: 0.0603 - AUC: 0.9954\n",
      "Epoch 9/20\n",
      "26126/26126 [==============================] - 2s 63us/sample - loss: 0.0535 - AUC: 0.9959\n",
      "Epoch 10/20\n",
      "26126/26126 [==============================] - 2s 62us/sample - loss: 0.0483 - AUC: 0.9967\n",
      "Epoch 11/20\n",
      "26126/26126 [==============================] - 2s 64us/sample - loss: 0.0427 - AUC: 0.9972\n",
      "Epoch 12/20\n",
      "26126/26126 [==============================] - 2s 67us/sample - loss: 0.0383 - AUC: 0.9977\n",
      "Epoch 13/20\n",
      "26126/26126 [==============================] - 2s 66us/sample - loss: 0.0347 - AUC: 0.9979\n",
      "Epoch 14/20\n",
      "26126/26126 [==============================] - 2s 65us/sample - loss: 0.0322 - AUC: 0.9983\n",
      "Epoch 15/20\n",
      "26126/26126 [==============================] - 2s 64us/sample - loss: 0.0290 - AUC: 0.9984\n",
      "Epoch 16/20\n",
      "26126/26126 [==============================] - 2s 65us/sample - loss: 0.0272 - AUC: 0.9987\n",
      "Epoch 17/20\n",
      "26126/26126 [==============================] - 2s 66us/sample - loss: 0.0257 - AUC: 0.9988\n",
      "Epoch 18/20\n",
      "26126/26126 [==============================] - 2s 65us/sample - loss: 0.0250 - AUC: 0.9989\n",
      "Epoch 19/20\n",
      "26126/26126 [==============================] - 2s 66us/sample - loss: 0.0222 - AUC: 0.9990\n",
      "Epoch 20/20\n",
      "26126/26126 [==============================] - 2s 67us/sample - loss: 0.0206 - AUC: 0.9991\n",
      "ROC AUC: 0.619\n",
      "Brier loss: 0.019\n",
      "Running NN on antenatal for _lapgar\n",
      "Train on 25530 samples\n",
      "Epoch 1/20\n",
      "25530/25530 [==============================] - 2s 90us/sample - loss: 0.6308 - AUC: 0.7073\n",
      "Epoch 2/20\n",
      "25530/25530 [==============================] - 2s 69us/sample - loss: 0.5085 - AUC: 0.8387\n",
      "Epoch 3/20\n",
      "25530/25530 [==============================] - 2s 68us/sample - loss: 0.4240 - AUC: 0.8909\n",
      "Epoch 4/20\n",
      "25530/25530 [==============================] - 2s 66us/sample - loss: 0.3678 - AUC: 0.9184\n",
      "Epoch 5/20\n",
      "25530/25530 [==============================] - 2s 66us/sample - loss: 0.3242 - AUC: 0.9375\n",
      "Epoch 6/20\n",
      "25530/25530 [==============================] - 2s 67us/sample - loss: 0.2977 - AUC: 0.9473\n",
      "Epoch 7/20\n",
      "25530/25530 [==============================] - 2s 66us/sample - loss: 0.2790 - AUC: 0.9533\n",
      "Epoch 8/20\n",
      "25530/25530 [==============================] - 2s 65us/sample - loss: 0.2622 - AUC: 0.9587\n",
      "Epoch 9/20\n",
      "25530/25530 [==============================] - 2s 67us/sample - loss: 0.2529 - AUC: 0.9612\n",
      "Epoch 10/20\n",
      "25530/25530 [==============================] - 2s 63us/sample - loss: 0.2415 - AUC: 0.9645\n",
      "Epoch 11/20\n",
      "25530/25530 [==============================] - 2s 64us/sample - loss: 0.2345 - AUC: 0.9664\n",
      "Epoch 12/20\n",
      "25530/25530 [==============================] - 2s 70us/sample - loss: 0.2260 - AUC: 0.9687\n",
      "Epoch 13/20\n",
      "25530/25530 [==============================] - 2s 67us/sample - loss: 0.2196 - AUC: 0.9704\n",
      "Epoch 14/20\n",
      "25530/25530 [==============================] - 2s 66us/sample - loss: 0.2160 - AUC: 0.9712\n",
      "Epoch 15/20\n",
      "25530/25530 [==============================] - 2s 67us/sample - loss: 0.2108 - AUC: 0.9724\n",
      "Epoch 16/20\n",
      "25530/25530 [==============================] - 2s 68us/sample - loss: 0.2051 - AUC: 0.9738\n",
      "Epoch 17/20\n",
      "25530/25530 [==============================] - 2s 65us/sample - loss: 0.1985 - AUC: 0.9754\n",
      "Epoch 18/20\n",
      "25530/25530 [==============================] - 2s 67us/sample - loss: 0.1955 - AUC: 0.9759\n",
      "Epoch 19/20\n",
      "25530/25530 [==============================] - 2s 68us/sample - loss: 0.1927 - AUC: 0.9763\n",
      "Epoch 20/20\n",
      "25530/25530 [==============================] - 2s 65us/sample - loss: 0.1877 - AUC: 0.9776\n",
      "ROC AUC: 0.557\n",
      "Brier loss: 0.058\n",
      "Running NN on antenatal for _perinataldeath\n",
      "Train on 26190 samples\n",
      "Epoch 1/20\n",
      "26190/26190 [==============================] - 2s 88us/sample - loss: 0.5957 - AUC: 0.7492\n",
      "Epoch 2/20\n",
      "26190/26190 [==============================] - 2s 65us/sample - loss: 0.4880 - AUC: 0.8495\n",
      "Epoch 3/20\n",
      "26190/26190 [==============================] - 2s 64us/sample - loss: 0.4258 - AUC: 0.8888\n",
      "Epoch 4/20\n",
      "26190/26190 [==============================] - 2s 65us/sample - loss: 0.3910 - AUC: 0.9065\n",
      "Epoch 5/20\n",
      "26190/26190 [==============================] - 2s 65us/sample - loss: 0.3642 - AUC: 0.9191\n",
      "Epoch 6/20\n",
      "26190/26190 [==============================] - 2s 63us/sample - loss: 0.3420 - AUC: 0.9288\n",
      "Epoch 7/20\n",
      "26190/26190 [==============================] - 2s 65us/sample - loss: 0.3252 - AUC: 0.9356\n",
      "Epoch 8/20\n",
      "26190/26190 [==============================] - 2s 63us/sample - loss: 0.3116 - AUC: 0.9405\n",
      "Epoch 9/20\n",
      "26190/26190 [==============================] - 2s 64us/sample - loss: 0.2997 - AUC: 0.9449\n",
      "Epoch 10/20\n",
      "26190/26190 [==============================] - 2s 64us/sample - loss: 0.2885 - AUC: 0.9488\n",
      "Epoch 11/20\n",
      "26190/26190 [==============================] - 2s 62us/sample - loss: 0.2785 - AUC: 0.9524\n",
      "Epoch 12/20\n",
      "26190/26190 [==============================] - 2s 60us/sample - loss: 0.2708 - AUC: 0.9548\n",
      "Epoch 13/20\n",
      "26190/26190 [==============================] - 2s 67us/sample - loss: 0.2603 - AUC: 0.9586\n",
      "Epoch 14/20\n",
      "26190/26190 [==============================] - 2s 65us/sample - loss: 0.2526 - AUC: 0.9609\n",
      "Epoch 15/20\n",
      "26190/26190 [==============================] - 2s 65us/sample - loss: 0.2469 - AUC: 0.9627\n",
      "Epoch 16/20\n",
      "26190/26190 [==============================] - 2s 65us/sample - loss: 0.2366 - AUC: 0.9659\n",
      "Epoch 17/20\n",
      "26190/26190 [==============================] - 2s 63us/sample - loss: 0.2294 - AUC: 0.9681\n",
      "Epoch 18/20\n",
      "26190/26190 [==============================] - 2s 64us/sample - loss: 0.2227 - AUC: 0.9700\n",
      "Epoch 19/20\n",
      "26190/26190 [==============================] - 2s 64us/sample - loss: 0.2162 - AUC: 0.9717\n",
      "Epoch 20/20\n",
      "26190/26190 [==============================] - 2s 63us/sample - loss: 0.2101 - AUC: 0.9734\n",
      "ROC AUC: 0.664\n",
      "Brier loss: 0.08\n",
      "Running NN on antenatal for _resus\n",
      "Train on 25064 samples\n",
      "Epoch 1/20\n",
      "25064/25064 [==============================] - 2s 87us/sample - loss: 0.6409 - AUC: 0.6855\n",
      "Epoch 2/20\n",
      "25064/25064 [==============================] - 2s 66us/sample - loss: 0.5603 - AUC: 0.7930\n",
      "Epoch 3/20\n",
      "25064/25064 [==============================] - 2s 68us/sample - loss: 0.4901 - AUC: 0.8503\n",
      "Epoch 4/20\n",
      "25064/25064 [==============================] - 2s 66us/sample - loss: 0.4430 - AUC: 0.8798\n",
      "Epoch 5/20\n",
      "25064/25064 [==============================] - 2s 64us/sample - loss: 0.4085 - AUC: 0.8982\n",
      "Epoch 6/20\n",
      "25064/25064 [==============================] - 2s 66us/sample - loss: 0.3827 - AUC: 0.9109\n",
      "Epoch 7/20\n",
      "25064/25064 [==============================] - 2s 64us/sample - loss: 0.3634 - AUC: 0.9197\n",
      "Epoch 8/20\n",
      "25064/25064 [==============================] - 2s 65us/sample - loss: 0.3509 - AUC: 0.9247\n",
      "Epoch 9/20\n",
      "25064/25064 [==============================] - 2s 68us/sample - loss: 0.3386 - AUC: 0.9298\n",
      "Epoch 10/20\n",
      "25064/25064 [==============================] - 2s 67us/sample - loss: 0.3290 - AUC: 0.9336\n",
      "Epoch 11/20\n",
      "25064/25064 [==============================] - 2s 66us/sample - loss: 0.3218 - AUC: 0.9364\n",
      "Epoch 12/20\n",
      "25064/25064 [==============================] - 2s 68us/sample - loss: 0.3123 - AUC: 0.9400\n",
      "Epoch 13/20\n",
      "25064/25064 [==============================] - 2s 64us/sample - loss: 0.3070 - AUC: 0.9420\n",
      "Epoch 14/20\n",
      "25064/25064 [==============================] - 2s 67us/sample - loss: 0.3010 - AUC: 0.9443\n",
      "Epoch 15/20\n",
      "25064/25064 [==============================] - 2s 64us/sample - loss: 0.2954 - AUC: 0.9464\n",
      "Epoch 16/20\n",
      "25064/25064 [==============================] - 2s 66us/sample - loss: 0.2912 - AUC: 0.9476\n",
      "Epoch 17/20\n",
      "25064/25064 [==============================] - 2s 64us/sample - loss: 0.2870 - AUC: 0.9492\n",
      "Epoch 18/20\n",
      "25064/25064 [==============================] - 2s 63us/sample - loss: 0.2815 - AUC: 0.9511\n",
      "Epoch 19/20\n",
      "25064/25064 [==============================] - 2s 65us/sample - loss: 0.2784 - AUC: 0.9521\n",
      "Epoch 20/20\n",
      "25064/25064 [==============================] - 2s 64us/sample - loss: 0.2765 - AUC: 0.9527\n",
      "ROC AUC: 0.551\n",
      "Brier loss: 0.113\n",
      "Running NN on antenatal_growth for _hie\n",
      "Train on 25732 samples\n",
      "Epoch 1/20\n",
      "25732/25732 [==============================] - 2s 66us/sample - loss: 0.4692 - AUC: 0.8621\n",
      "Epoch 2/20\n",
      "25732/25732 [==============================] - 1s 44us/sample - loss: 0.2814 - AUC: 0.9498\n",
      "Epoch 3/20\n",
      "25732/25732 [==============================] - 1s 46us/sample - loss: 0.2059 - AUC: 0.9700\n",
      "Epoch 4/20\n",
      "25732/25732 [==============================] - 1s 43us/sample - loss: 0.1730 - AUC: 0.9769\n",
      "Epoch 5/20\n",
      "25732/25732 [==============================] - 1s 41us/sample - loss: 0.1560 - AUC: 0.9797\n",
      "Epoch 6/20\n",
      "25732/25732 [==============================] - 1s 41us/sample - loss: 0.1429 - AUC: 0.9821\n",
      "Epoch 7/20\n",
      "25732/25732 [==============================] - 1s 40us/sample - loss: 0.1337 - AUC: 0.9835\n",
      "Epoch 8/20\n",
      "25732/25732 [==============================] - 1s 40us/sample - loss: 0.1238 - AUC: 0.9852\n",
      "Epoch 9/20\n",
      "25732/25732 [==============================] - 1s 40us/sample - loss: 0.1144 - AUC: 0.9867\n",
      "Epoch 10/20\n",
      "25732/25732 [==============================] - 1s 40us/sample - loss: 0.1067 - AUC: 0.9880\n",
      "Epoch 11/20\n",
      "25732/25732 [==============================] - 1s 41us/sample - loss: 0.1003 - AUC: 0.9893\n",
      "Epoch 12/20\n",
      "25732/25732 [==============================] - 1s 41us/sample - loss: 0.0940 - AUC: 0.9903\n",
      "Epoch 13/20\n",
      "25732/25732 [==============================] - 1s 40us/sample - loss: 0.0895 - AUC: 0.9910\n",
      "Epoch 14/20\n",
      "25732/25732 [==============================] - 1s 40us/sample - loss: 0.0845 - AUC: 0.9916\n",
      "Epoch 15/20\n",
      "25732/25732 [==============================] - 1s 40us/sample - loss: 0.0809 - AUC: 0.9923\n",
      "Epoch 16/20\n",
      "25732/25732 [==============================] - 1s 41us/sample - loss: 0.0780 - AUC: 0.9926\n",
      "Epoch 17/20\n",
      "25732/25732 [==============================] - 1s 42us/sample - loss: 0.0748 - AUC: 0.9929\n",
      "Epoch 18/20\n",
      "25732/25732 [==============================] - 1s 41us/sample - loss: 0.0720 - AUC: 0.9936\n",
      "Epoch 19/20\n",
      "25732/25732 [==============================] - 1s 44us/sample - loss: 0.0702 - AUC: 0.9935\n",
      "Epoch 20/20\n",
      "25732/25732 [==============================] - 1s 46us/sample - loss: 0.0685 - AUC: 0.9940\n",
      "ROC AUC: 0.619\n",
      "Brier loss: 0.033\n",
      "Running NN on antenatal_growth for _lapgar\n",
      "Train on 25078 samples\n",
      "Epoch 1/20\n",
      "25078/25078 [==============================] - 2s 83us/sample - loss: 0.6470 - AUC: 0.6771\n",
      "Epoch 2/20\n",
      "25078/25078 [==============================] - 2s 66us/sample - loss: 0.5494 - AUC: 0.8047\n",
      "Epoch 3/20\n",
      "25078/25078 [==============================] - 2s 64us/sample - loss: 0.4587 - AUC: 0.8728\n",
      "Epoch 4/20\n",
      "25078/25078 [==============================] - 2s 65us/sample - loss: 0.4023 - AUC: 0.9027\n",
      "Epoch 5/20\n",
      "25078/25078 [==============================] - 2s 66us/sample - loss: 0.3684 - AUC: 0.9183\n",
      "Epoch 6/20\n",
      "25078/25078 [==============================] - 2s 65us/sample - loss: 0.3460 - AUC: 0.9274\n",
      "Epoch 7/20\n",
      "25078/25078 [==============================] - 2s 64us/sample - loss: 0.3269 - AUC: 0.9352\n",
      "Epoch 8/20\n",
      "25078/25078 [==============================] - 2s 64us/sample - loss: 0.3139 - AUC: 0.9402\n",
      "Epoch 9/20\n",
      "25078/25078 [==============================] - 2s 63us/sample - loss: 0.3003 - AUC: 0.9452\n",
      "Epoch 10/20\n",
      "25078/25078 [==============================] - 2s 62us/sample - loss: 0.2905 - AUC: 0.9485\n",
      "Epoch 11/20\n",
      "25078/25078 [==============================] - 2s 66us/sample - loss: 0.2815 - AUC: 0.9517\n",
      "Epoch 12/20\n",
      "25078/25078 [==============================] - 2s 68us/sample - loss: 0.2716 - AUC: 0.9549\n",
      "Epoch 13/20\n",
      "25078/25078 [==============================] - 2s 65us/sample - loss: 0.2644 - AUC: 0.9572\n",
      "Epoch 14/20\n",
      "25078/25078 [==============================] - 2s 66us/sample - loss: 0.2572 - AUC: 0.9594\n",
      "Epoch 15/20\n",
      "25078/25078 [==============================] - 2s 65us/sample - loss: 0.2510 - AUC: 0.9611\n",
      "Epoch 16/20\n",
      "25078/25078 [==============================] - 2s 63us/sample - loss: 0.2439 - AUC: 0.9633\n",
      "Epoch 17/20\n",
      "25078/25078 [==============================] - 2s 62us/sample - loss: 0.2366 - AUC: 0.9654\n",
      "Epoch 18/20\n",
      "25078/25078 [==============================] - 2s 66us/sample - loss: 0.2331 - AUC: 0.9663\n",
      "Epoch 19/20\n",
      "25078/25078 [==============================] - 2s 66us/sample - loss: 0.2276 - AUC: 0.9679\n",
      "Epoch 20/20\n",
      "25078/25078 [==============================] - 2s 66us/sample - loss: 0.2233 - AUC: 0.9689\n",
      "ROC AUC: 0.518\n",
      "Brier loss: 0.098\n",
      "Running NN on antenatal_growth for _perinataldeath\n",
      "Train on 25938 samples\n",
      "Epoch 1/20\n",
      "25938/25938 [==============================] - 2s 83us/sample - loss: 0.4553 - AUC: 0.8710\n",
      "Epoch 2/20\n",
      "25938/25938 [==============================] - 2s 65us/sample - loss: 0.1870 - AUC: 0.9771\n",
      "Epoch 3/20\n",
      "25938/25938 [==============================] - 2s 64us/sample - loss: 0.1160 - AUC: 0.9883\n",
      "Epoch 4/20\n",
      "25938/25938 [==============================] - 2s 66us/sample - loss: 0.0844 - AUC: 0.9926\n",
      "Epoch 5/20\n",
      "25938/25938 [==============================] - 2s 65us/sample - loss: 0.0656 - AUC: 0.9946\n",
      "Epoch 6/20\n",
      "25938/25938 [==============================] - 2s 66us/sample - loss: 0.0542 - AUC: 0.9960\n",
      "Epoch 7/20\n",
      "25938/25938 [==============================] - 2s 66us/sample - loss: 0.0464 - AUC: 0.9965\n",
      "Epoch 8/20\n",
      "25938/25938 [==============================] - 2s 66us/sample - loss: 0.0409 - AUC: 0.9972\n",
      "Epoch 9/20\n",
      "25938/25938 [==============================] - 2s 64us/sample - loss: 0.0361 - AUC: 0.9976\n",
      "Epoch 10/20\n",
      "25938/25938 [==============================] - 2s 65us/sample - loss: 0.0319 - AUC: 0.9980\n",
      "Epoch 11/20\n",
      "25938/25938 [==============================] - 2s 63us/sample - loss: 0.0287 - AUC: 0.9983\n",
      "Epoch 12/20\n",
      "25938/25938 [==============================] - 2s 62us/sample - loss: 0.0264 - AUC: 0.9986\n",
      "Epoch 13/20\n",
      "25938/25938 [==============================] - 2s 62us/sample - loss: 0.0240 - AUC: 0.9988\n",
      "Epoch 14/20\n",
      "25938/25938 [==============================] - 2s 63us/sample - loss: 0.0224 - AUC: 0.9989\n",
      "Epoch 15/20\n",
      "25938/25938 [==============================] - 2s 66us/sample - loss: 0.0207 - AUC: 0.9990\n",
      "Epoch 16/20\n",
      "25938/25938 [==============================] - 2s 66us/sample - loss: 0.0196 - AUC: 0.9993\n",
      "Epoch 17/20\n",
      "25938/25938 [==============================] - 2s 65us/sample - loss: 0.0172 - AUC: 0.9993\n",
      "Epoch 18/20\n",
      "25938/25938 [==============================] - 2s 66us/sample - loss: 0.0169 - AUC: 0.9994\n",
      "Epoch 19/20\n",
      "25938/25938 [==============================] - 2s 64us/sample - loss: 0.0154 - AUC: 0.9995\n",
      "Epoch 20/20\n",
      "25938/25938 [==============================] - 2s 65us/sample - loss: 0.0143 - AUC: 0.9995\n",
      "ROC AUC: 0.531\n",
      "Brier loss: 0.014\n",
      "Running NN on antenatal_growth for _resus\n",
      "Train on 24686 samples\n",
      "Epoch 1/20\n",
      "24686/24686 [==============================] - 2s 89us/sample - loss: 0.6457 - AUC: 0.6770\n",
      "Epoch 2/20\n",
      "24686/24686 [==============================] - 2s 65us/sample - loss: 0.5651 - AUC: 0.7854\n",
      "Epoch 3/20\n",
      "24686/24686 [==============================] - 2s 64us/sample - loss: 0.4909 - AUC: 0.8496\n",
      "Epoch 4/20\n",
      "24686/24686 [==============================] - 2s 63us/sample - loss: 0.4346 - AUC: 0.8854\n",
      "Epoch 5/20\n",
      "24686/24686 [==============================] - 2s 68us/sample - loss: 0.3958 - AUC: 0.9052\n",
      "Epoch 6/20\n",
      "24686/24686 [==============================] - 2s 62us/sample - loss: 0.3689 - AUC: 0.9174\n",
      "Epoch 7/20\n",
      "24686/24686 [==============================] - 2s 64us/sample - loss: 0.3481 - AUC: 0.9264\n",
      "Epoch 8/20\n",
      "24686/24686 [==============================] - 2s 61us/sample - loss: 0.3326 - AUC: 0.9325\n",
      "Epoch 9/20\n",
      "24686/24686 [==============================] - 2s 65us/sample - loss: 0.3207 - AUC: 0.9370\n",
      "Epoch 10/20\n",
      "24686/24686 [==============================] - 2s 65us/sample - loss: 0.3074 - AUC: 0.9421\n",
      "Epoch 11/20\n",
      "24686/24686 [==============================] - 2s 66us/sample - loss: 0.2997 - AUC: 0.9448\n",
      "Epoch 12/20\n",
      "24686/24686 [==============================] - 2s 66us/sample - loss: 0.2928 - AUC: 0.9470\n",
      "Epoch 13/20\n",
      "24686/24686 [==============================] - 2s 62us/sample - loss: 0.2834 - AUC: 0.9505\n",
      "Epoch 14/20\n",
      "24686/24686 [==============================] - 2s 65us/sample - loss: 0.2770 - AUC: 0.9526\n",
      "Epoch 15/20\n",
      "24686/24686 [==============================] - 2s 63us/sample - loss: 0.2708 - AUC: 0.9546\n",
      "Epoch 16/20\n",
      "24686/24686 [==============================] - 2s 64us/sample - loss: 0.2634 - AUC: 0.9570\n",
      "Epoch 17/20\n",
      "24686/24686 [==============================] - 2s 68us/sample - loss: 0.2608 - AUC: 0.9575\n",
      "Epoch 18/20\n",
      "24686/24686 [==============================] - 2s 65us/sample - loss: 0.2533 - AUC: 0.9598\n",
      "Epoch 19/20\n",
      "24686/24686 [==============================] - 2s 63us/sample - loss: 0.2529 - AUC: 0.9598\n",
      "Epoch 20/20\n",
      "24686/24686 [==============================] - 2s 67us/sample - loss: 0.2455 - AUC: 0.9622\n",
      "ROC AUC: 0.554\n",
      "Brier loss: 0.079\n",
      "Running NN on antenatal_intrapartum for _hie\n",
      "Train on 24472 samples\n",
      "Epoch 1/20\n",
      "24472/24472 [==============================] - 2s 61us/sample - loss: 0.4353 - AUC: 0.8848\n",
      "Epoch 2/20\n",
      "24472/24472 [==============================] - 1s 43us/sample - loss: 0.2701 - AUC: 0.9561\n",
      "Epoch 3/20\n",
      "24472/24472 [==============================] - 1s 46us/sample - loss: 0.1813 - AUC: 0.9781\n",
      "Epoch 4/20\n",
      "24472/24472 [==============================] - 1s 42us/sample - loss: 0.1322 - AUC: 0.9863\n",
      "Epoch 5/20\n",
      "24472/24472 [==============================] - 1s 45us/sample - loss: 0.1052 - AUC: 0.9899\n",
      "Epoch 6/20\n",
      "24472/24472 [==============================] - 1s 46us/sample - loss: 0.0865 - AUC: 0.9924\n",
      "Epoch 7/20\n",
      "24472/24472 [==============================] - 1s 46us/sample - loss: 0.0740 - AUC: 0.9939\n",
      "Epoch 8/20\n",
      "24472/24472 [==============================] - 1s 46us/sample - loss: 0.0654 - AUC: 0.9951\n",
      "Epoch 9/20\n",
      "24472/24472 [==============================] - 1s 46us/sample - loss: 0.0580 - AUC: 0.9959\n",
      "Epoch 10/20\n",
      "24472/24472 [==============================] - 1s 45us/sample - loss: 0.0522 - AUC: 0.9963\n",
      "Epoch 11/20\n",
      "24472/24472 [==============================] - 1s 45us/sample - loss: 0.0476 - AUC: 0.9970\n",
      "Epoch 12/20\n",
      "24472/24472 [==============================] - 1s 46us/sample - loss: 0.0441 - AUC: 0.9972\n",
      "Epoch 13/20\n",
      "24472/24472 [==============================] - 1s 50us/sample - loss: 0.0398 - AUC: 0.9975\n",
      "Epoch 14/20\n",
      "24472/24472 [==============================] - 1s 49us/sample - loss: 0.0385 - AUC: 0.9977\n",
      "Epoch 15/20\n",
      "24472/24472 [==============================] - 1s 48us/sample - loss: 0.0345 - AUC: 0.9981\n",
      "Epoch 16/20\n",
      "24472/24472 [==============================] - 1s 49us/sample - loss: 0.0316 - AUC: 0.9985\n",
      "Epoch 17/20\n",
      "24472/24472 [==============================] - 1s 48us/sample - loss: 0.0304 - AUC: 0.9985\n",
      "Epoch 18/20\n",
      "24472/24472 [==============================] - 1s 48us/sample - loss: 0.0275 - AUC: 0.9987\n",
      "Epoch 19/20\n",
      "24472/24472 [==============================] - 1s 45us/sample - loss: 0.0262 - AUC: 0.9989\n",
      "Epoch 20/20\n",
      "24472/24472 [==============================] - 1s 45us/sample - loss: 0.0250 - AUC: 0.9990\n",
      "ROC AUC: 0.606\n",
      "Brier loss: 0.018\n",
      "Running NN on antenatal_intrapartum for _lapgar\n",
      "Train on 23878 samples\n",
      "Epoch 1/20\n",
      "23878/23878 [==============================] - 2s 77us/sample - loss: 0.6480 - AUC: 0.6697\n",
      "Epoch 2/20\n",
      "23878/23878 [==============================] - 1s 63us/sample - loss: 0.5892 - AUC: 0.7566\n",
      "Epoch 3/20\n",
      "23878/23878 [==============================] - 2s 66us/sample - loss: 0.5141 - AUC: 0.8322\n",
      "Epoch 4/20\n",
      "23878/23878 [==============================] - 2s 64us/sample - loss: 0.4485 - AUC: 0.8746\n",
      "Epoch 5/20\n",
      "23878/23878 [==============================] - 1s 62us/sample - loss: 0.4027 - AUC: 0.8996\n",
      "Epoch 6/20\n",
      "23878/23878 [==============================] - 1s 62us/sample - loss: 0.3730 - AUC: 0.9137\n",
      "Epoch 7/20\n",
      "23878/23878 [==============================] - 1s 61us/sample - loss: 0.3528 - AUC: 0.9220\n",
      "Epoch 8/20\n",
      "23878/23878 [==============================] - 1s 62us/sample - loss: 0.3374 - AUC: 0.9282\n",
      "Epoch 9/20\n",
      "23878/23878 [==============================] - 2s 65us/sample - loss: 0.3260 - AUC: 0.9324\n",
      "Epoch 10/20\n",
      "23878/23878 [==============================] - 2s 64us/sample - loss: 0.3174 - AUC: 0.9356\n",
      "Epoch 11/20\n",
      "23878/23878 [==============================] - 1s 62us/sample - loss: 0.3097 - AUC: 0.9384\n",
      "Epoch 12/20\n",
      "23878/23878 [==============================] - 1s 61us/sample - loss: 0.3030 - AUC: 0.9408\n",
      "Epoch 13/20\n",
      "23878/23878 [==============================] - 2s 64us/sample - loss: 0.2983 - AUC: 0.9425\n",
      "Epoch 14/20\n",
      "23878/23878 [==============================] - 2s 65us/sample - loss: 0.2929 - AUC: 0.9445\n",
      "Epoch 15/20\n",
      "23878/23878 [==============================] - 2s 63us/sample - loss: 0.2903 - AUC: 0.9452\n",
      "Epoch 16/20\n",
      "23878/23878 [==============================] - 1s 60us/sample - loss: 0.2856 - AUC: 0.9469\n",
      "Epoch 17/20\n",
      "23878/23878 [==============================] - 1s 61us/sample - loss: 0.2830 - AUC: 0.9478\n",
      "Epoch 18/20\n",
      "23878/23878 [==============================] - 2s 64us/sample - loss: 0.2785 - AUC: 0.9496\n",
      "Epoch 19/20\n",
      "23878/23878 [==============================] - 1s 62us/sample - loss: 0.2759 - AUC: 0.9505\n",
      "Epoch 20/20\n",
      "23878/23878 [==============================] - 1s 62us/sample - loss: 0.2728 - AUC: 0.9515\n",
      "ROC AUC: 0.542\n",
      "Brier loss: 0.089\n",
      "Running NN on antenatal_intrapartum for _perinataldeath\n",
      "Train on 24492 samples\n",
      "Epoch 1/20\n",
      "24492/24492 [==============================] - 2s 73us/sample - loss: 0.5346 - AUC: 0.8123\n",
      "Epoch 2/20\n",
      "24492/24492 [==============================] - 1s 52us/sample - loss: 0.4536 - AUC: 0.8701\n",
      "Epoch 3/20\n",
      "24492/24492 [==============================] - 1s 52us/sample - loss: 0.4068 - AUC: 0.8984\n",
      "Epoch 4/20\n",
      "24492/24492 [==============================] - 1s 55us/sample - loss: 0.3622 - AUC: 0.9215\n",
      "Epoch 5/20\n",
      "24492/24492 [==============================] - 1s 53us/sample - loss: 0.3244 - AUC: 0.9379\n",
      "Epoch 6/20\n",
      "24492/24492 [==============================] - 1s 47us/sample - loss: 0.2953 - AUC: 0.9487\n",
      "Epoch 7/20\n",
      "24492/24492 [==============================] - 1s 50us/sample - loss: 0.2742 - AUC: 0.9553\n",
      "Epoch 8/20\n",
      "24492/24492 [==============================] - 1s 53us/sample - loss: 0.2569 - AUC: 0.9603\n",
      "Epoch 9/20\n",
      "24492/24492 [==============================] - 1s 51us/sample - loss: 0.2417 - AUC: 0.9646\n",
      "Epoch 10/20\n",
      "24492/24492 [==============================] - 1s 54us/sample - loss: 0.2308 - AUC: 0.9675\n",
      "Epoch 11/20\n",
      "24492/24492 [==============================] - 1s 56us/sample - loss: 0.2207 - AUC: 0.9700\n",
      "Epoch 12/20\n",
      "24492/24492 [==============================] - 1s 53us/sample - loss: 0.2084 - AUC: 0.9733\n",
      "Epoch 13/20\n",
      "24492/24492 [==============================] - 1s 53us/sample - loss: 0.1988 - AUC: 0.9758\n",
      "Epoch 14/20\n",
      "24492/24492 [==============================] - 1s 55us/sample - loss: 0.1888 - AUC: 0.9782\n",
      "Epoch 15/20\n",
      "24492/24492 [==============================] - 1s 56us/sample - loss: 0.1805 - AUC: 0.9800\n",
      "Epoch 16/20\n",
      "24492/24492 [==============================] - 1s 55us/sample - loss: 0.1718 - AUC: 0.9820\n",
      "Epoch 17/20\n",
      "24492/24492 [==============================] - 1s 51us/sample - loss: 0.1644 - AUC: 0.9835\n",
      "Epoch 18/20\n",
      "24492/24492 [==============================] - 1s 52us/sample - loss: 0.1571 - AUC: 0.9849\n",
      "Epoch 19/20\n",
      "24492/24492 [==============================] - 1s 55us/sample - loss: 0.1531 - AUC: 0.9857\n",
      "Epoch 20/20\n",
      "24492/24492 [==============================] - 1s 52us/sample - loss: 0.1469 - AUC: 0.9867\n",
      "ROC AUC: 0.7\n",
      "Brier loss: 0.055\n",
      "Running NN on antenatal_intrapartum for _resus\n",
      "Train on 23520 samples\n",
      "Epoch 1/20\n",
      "23520/23520 [==============================] - 1s 59us/sample - loss: 0.6313 - AUC: 0.7056\n",
      "Epoch 2/20\n",
      "23520/23520 [==============================] - 1s 43us/sample - loss: 0.5426 - AUC: 0.8079\n",
      "Epoch 3/20\n",
      "23520/23520 [==============================] - 1s 41us/sample - loss: 0.4850 - AUC: 0.8494\n",
      "Epoch 4/20\n",
      "23520/23520 [==============================] - 1s 41us/sample - loss: 0.4525 - AUC: 0.8693\n",
      "Epoch 5/20\n",
      "23520/23520 [==============================] - 1s 41us/sample - loss: 0.4324 - AUC: 0.8798\n",
      "Epoch 6/20\n",
      "23520/23520 [==============================] - 1s 41us/sample - loss: 0.4185 - AUC: 0.8871\n",
      "Epoch 7/20\n",
      "23520/23520 [==============================] - 1s 40us/sample - loss: 0.4065 - AUC: 0.8937\n",
      "Epoch 8/20\n",
      "23520/23520 [==============================] - 1s 39us/sample - loss: 0.3952 - AUC: 0.8999\n",
      "Epoch 9/20\n",
      "23520/23520 [==============================] - 1s 40us/sample - loss: 0.3862 - AUC: 0.9040\n",
      "Epoch 10/20\n",
      "23520/23520 [==============================] - 1s 41us/sample - loss: 0.3750 - AUC: 0.9094\n",
      "Epoch 11/20\n",
      "23520/23520 [==============================] - 1s 41us/sample - loss: 0.3658 - AUC: 0.9135\n",
      "Epoch 12/20\n",
      "23520/23520 [==============================] - 1s 38us/sample - loss: 0.3550 - AUC: 0.9180\n",
      "Epoch 13/20\n",
      "23520/23520 [==============================] - 1s 39us/sample - loss: 0.3458 - AUC: 0.9217\n",
      "Epoch 14/20\n",
      "23520/23520 [==============================] - 1s 43us/sample - loss: 0.3363 - AUC: 0.9252\n",
      "Epoch 15/20\n",
      "23520/23520 [==============================] - 1s 43us/sample - loss: 0.3265 - AUC: 0.9291\n",
      "Epoch 16/20\n",
      "23520/23520 [==============================] - 1s 43us/sample - loss: 0.3192 - AUC: 0.9314\n",
      "Epoch 17/20\n",
      "23520/23520 [==============================] - 1s 40us/sample - loss: 0.3116 - AUC: 0.9344\n",
      "Epoch 18/20\n",
      "23520/23520 [==============================] - 1s 40us/sample - loss: 0.3045 - AUC: 0.9368\n",
      "Epoch 19/20\n",
      "23520/23520 [==============================] - 1s 40us/sample - loss: 0.2934 - AUC: 0.9410\n",
      "Epoch 20/20\n",
      "23520/23520 [==============================] - 1s 41us/sample - loss: 0.2854 - AUC: 0.9440\n",
      "ROC AUC: 0.581\n",
      "Brier loss: 0.083\n"
     ]
    }
   ],
   "source": [
    "for data in [\"antenatal\", \"antenatal_growth\", \"antenatal_intrapartum\"]:    \n",
    "    for outcome in ['_hie', '_lapgar', '_perinataldeath', '_resus']:\n",
    "        \n",
    "        print(\"Running NN on {} for {}\".format(data, outcome))\n",
    "        \n",
    "        # read in data\n",
    "        train = pd.read_csv(\"data/{}{}_train.csv\".format(data, outcome), index_col=0).astype('float32')\n",
    "        test = pd.read_csv(\"data/{}{}_test.csv\".format(data, outcome), index_col=0).astype('float32')\n",
    "        train_y = train.pop(outcome)\n",
    "        test_y = test.pop(outcome)\n",
    "        \n",
    "        # evaluate model\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(len(train.columns), activation='relu'),\n",
    "            tf.keras.layers.Dense(len(train.columns), activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "    \n",
    "        # train model\n",
    "        model.fit(tf.convert_to_tensor(train.to_numpy(), np.float32), tf.convert_to_tensor(train_y.to_numpy(), np.float32), epochs=20)\n",
    "    \n",
    "        # predict test probabilities\n",
    "        y_test_pred = model.predict(tf.convert_to_tensor(test.to_numpy(), np.float32)).flatten()\n",
    "    \n",
    "        # calculate roc auc metric\n",
    "        fpr, tpr, thresholds = roc_curve(test_y, y_test_pred)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "        # calculate brier loss for probability accuracy\n",
    "        brier_loss = brier_score_loss(test_y, y_test_pred)\n",
    "        \n",
    "        # write out probs for delong test to obtain CIs (R)\n",
    "        pd.DataFrame({\"Prob\" : y_test_pred, \"{}{}\".format(data, outcome): test_y}).to_csv(\"data/{}{}.NN.csv\".format(data, outcome))\n",
    "    \n",
    "        print(\"ROC AUC: {}\\nBrier loss: {}\".format(np.round(roc_auc, 3), np.round(brier_loss, 3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
